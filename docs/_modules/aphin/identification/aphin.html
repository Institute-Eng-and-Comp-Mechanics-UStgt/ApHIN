<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>aphin.identification.aphin &mdash; ApHIN 0.1.3 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=360bc84d"></script>
        <script src="../../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            ApHIN
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../modules.html">aphin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contact.html">Contact</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">ApHIN</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">aphin.identification.aphin</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for aphin.identification.aphin</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">TruncatedSVD</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># own modules</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">PHBasemodel</span>
<span class="kn">from</span> <span class="nn">aphin.layers</span> <span class="kn">import</span> <span class="n">PHLayer</span>
<span class="kn">from</span> <span class="nn">aphin.utils</span> <span class="kn">import</span> <span class="n">integrators</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">()</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>


<div class="viewcode-block" id="APHIN">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN">[docs]</a>
<span class="k">class</span> <span class="nc">APHIN</span><span class="p">(</span><span class="n">PHBasemodel</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Autoencoder-based port-Hamiltonian Identification Network (ApHIN)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reduced_order</span><span class="p">,</span>
        <span class="n">pca_order</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">u</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">mu</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">system_layer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">layer_sizes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span>
        <span class="n">pca_scaling</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">use_pca</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">pca_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">l_rec</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">l_dz</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">l_dx</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">l1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">l2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Model to discover low-dimensional dynamics of a high-dimensional system using autoencoders and</span>
<span class="sd">        a layer for identification of other dynamical systems (see SystemLayer), e.g., a PHLayer (port-Hamiltonian)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        reduced_order : int</span>
<span class="sd">            Order of the reduced model.</span>
<span class="sd">        pca_order : int, optional</span>
<span class="sd">            Order of the PCA model.</span>
<span class="sd">        x : array-like, optional</span>
<span class="sd">            Input data (full states) with shape (n_sim*n_t, n_f) with n_sim simulation scenarios, n_t time steps, n_f features.</span>
<span class="sd">        u : array-like, optional</span>
<span class="sd">            System inputs with shape (n_sim*n_t, n_u) with n_sim simulation scenarios, n_t time steps, n_u inputs.</span>
<span class="sd">        mu : array-like, optional</span>
<span class="sd">            Parameter data (n_sim*n_t, n_mu).</span>
<span class="sd">        system_layer : SystemLayer or subclass instance, optional</span>
<span class="sd">            Instance that learns the reduced system in the latent space.</span>
<span class="sd">        layer_sizes : list of int, optional</span>
<span class="sd">            Layers of the dense neural network of the non-linear autoencoder part.</span>
<span class="sd">        activation : str, optional</span>
<span class="sd">            Activation function of the dense neural network of the non-linear autoencoder part.</span>
<span class="sd">        pca_scaling : bool, optional</span>
<span class="sd">            If PCA modes should be scaled according to singular values.</span>
<span class="sd">        use_pca : bool, optional</span>
<span class="sd">            If PCA (linear MOR) should be performed before/after the non-linear autoencoder part.</span>
<span class="sd">        pca_only : bool, optional</span>
<span class="sd">            If only PCA (linear MOR) should be performed instead of the non-linear autoencoder part.</span>
<span class="sd">        l_rec : float, optional</span>
<span class="sd">            Weight of the reconstruction loss.</span>
<span class="sd">        l_dz : float, optional</span>
<span class="sd">            Weight of the derivative loss in the latent space.</span>
<span class="sd">        l_dx : float, optional</span>
<span class="sd">            Weight of the derivative loss in the physical space.</span>
<span class="sd">        l1 : float, optional</span>
<span class="sd">            L1 regularization factor.</span>
<span class="sd">        l2 : float, optional</span>
<span class="sd">            L2 regularization factor.</span>
<span class="sd">        dtype : str, optional</span>
<span class="sd">            Data type for the model.</span>
<span class="sd">        kwargs : dict</span>
<span class="sd">            Additional keyword arguments.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># tf.keras.backend.set_floatx(dtype)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">APHIN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># general parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">system_optimizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">layer_sizes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span> <span class="o">=</span> <span class="n">layer_sizes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
        <span class="c1"># pca related parameters</span>
        <span class="k">if</span> <span class="n">pca_order</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pca_order</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">reduced_order</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduced_order</span> <span class="o">=</span> <span class="n">reduced_order</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pca_order</span> <span class="o">=</span> <span class="n">pca_order</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pca_scaling_individual</span> <span class="o">=</span> <span class="n">pca_scaling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_factor</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_pca</span> <span class="o">=</span> <span class="n">use_pca</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pca_only</span> <span class="o">=</span> <span class="n">pca_only</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pca_only</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_pca</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pca_order</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduced_order</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">system_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">system_layer</span> <span class="o">=</span> <span class="n">PHLayer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduced_order</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">system_layer</span> <span class="o">=</span> <span class="n">system_layer</span>
        <span class="c1"># weighting of the different losses</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l_rec</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">l_dz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">l_dx</span> <span class="o">=</span> <span class="n">l_rec</span><span class="p">,</span> <span class="n">l_dz</span><span class="p">,</span> <span class="n">l_dx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l1_l2</span><span class="p">(</span><span class="n">l1</span><span class="o">=</span><span class="n">l1</span><span class="p">,</span> <span class="n">l2</span><span class="o">=</span><span class="n">l2</span><span class="p">)</span>

        <span class="c1"># create the model</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_shape</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="k">if</span> <span class="n">u</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">u_shape</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="k">if</span> <span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu_shape</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">use_pca</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pca_order</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># some subclasses initialize weights before building the model</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;init_weights&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>

        <span class="c1"># create loss tracker</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_tracker</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rec_loss_tracker</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;rec_loss&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dz_loss_tracker</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;dz_loss&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dx_loss_tracker</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;dx_loss&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_loss_tracker</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;reg_loss&quot;</span><span class="p">)</span>

        <span class="c1"># decide which loss needs to be evaluated</span>
        <span class="c1"># only perform reconstruction if no identification loss is used</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">l_dx</span> <span class="o">==</span> <span class="mf">0.0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">l_dz</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">get_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_loss_rec</span>
        <span class="c1"># calculate loss for first order systems</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">get_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_loss</span>

        <span class="c1"># save parsed arguments</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_to_config</span><span class="p">(</span><span class="nb">locals</span><span class="p">())</span>

<div class="viewcode-block" id="APHIN.get_trainable_weights">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.get_trainable_weights">[docs]</a>
    <span class="k">def</span> <span class="nf">get_trainable_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the trainable weights of the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list</span>
<span class="sd">            List of trainable weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">trainable_weights</span>
            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">trainable_weights</span>
            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_network</span><span class="o">.</span><span class="n">trainable_weights</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="APHIN.build_model">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.build_model">[docs]</a>
    <span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build the model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like</span>
<span class="sd">            Full state with shape (n_samples, n_features).</span>
<span class="sd">        u : array-like, optional</span>
<span class="sd">            Inputs with shape (n_samples, n_inputs).</span>
<span class="sd">        mu : array-like, optional</span>
<span class="sd">            Parameters with shape (n_samples, n_params).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">x_input</span><span class="p">,</span> <span class="n">z_pca</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">z_dec</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_autoencoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># System inputs</span>
        <span class="k">if</span> <span class="n">u</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">u_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">u_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>

        <span class="c1"># Simulation parameters</span>
        <span class="k">if</span> <span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mu_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mu_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>

        <span class="n">dz_dt_system</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_layer</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">u_input</span><span class="p">,</span> <span class="n">mu_input</span><span class="p">)</span>

        <span class="c1"># linear autoencoder part from full to intermediate latent space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pca_encoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">x_input</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">z_pca</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;pca_encoder&quot;</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pca_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">z_dec</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;pca_decoder&quot;</span><span class="p">)</span>
        <span class="c1"># nonlinear autoencoder part from intermediate latent space to latent space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nonlinear_encoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">z_pca</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;nonlinear_encoder&quot;</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nonlinear_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">z_dec</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;nonlinear_decoder&quot;</span>
        <span class="p">)</span>
        <span class="c1"># global autoencoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">x_input</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;encoder&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;decoder&quot;</span><span class="p">)</span>
        <span class="c1"># network for discovery of dynamic system (e.g. pH system)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">system_network</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">z</span><span class="p">,</span> <span class="n">u_input</span><span class="p">,</span> <span class="n">mu_input</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="n">dz_dt_system</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;system&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="APHIN.build_autoencoder">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.build_autoencoder">[docs]</a>
    <span class="k">def</span> <span class="nf">build_autoencoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build the encoder and decoder of the autoencoder.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like</span>
<span class="sd">            Input data.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            Tuple containing inputs and outputs of the autoencoder.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span>
        <span class="c1"># first part of the encoder may consist of a linear projection based on PCA</span>
        <span class="n">z_pca</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_pca_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_input</span><span class="p">)</span>
        <span class="c1"># second part of the encoder and first part of the decoder is a nonlinear part</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">z_dec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_nonlinear_autoencoder</span><span class="p">(</span><span class="n">z_pca</span><span class="p">)</span>
        <span class="c1"># second part of the decoder is a back projection based on PCA</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_pca_decoder</span><span class="p">(</span><span class="n">z_dec</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x_input</span><span class="p">,</span> <span class="n">z_pca</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">z_dec</span><span class="p">,</span> <span class="n">x</span></div>


<div class="viewcode-block" id="APHIN.build_pca_encoder">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.build_pca_encoder">[docs]</a>
    <span class="k">def</span> <span class="nf">build_pca_encoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_input</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the PCA of the data and build a linear encoder which is equivalent to the PCA.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like</span>
<span class="sd">            Input data.</span>
<span class="sd">        x_input : tf.Tensor</span>
<span class="sd">            Input tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tf.Tensor</span>
<span class="sd">            Encoded PCA tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># if PCA is used, calculate the PCA and build a linear encoder</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_pca</span><span class="p">:</span>
            <span class="c1"># calculate the PCA</span>
            <span class="n">pca</span> <span class="o">=</span> <span class="n">TruncatedSVD</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pca_order</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="c1"># use the projection matrix as linear encoder</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">singular_values</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">singular_values_</span>
            <span class="n">z_pca</span> <span class="o">=</span> <span class="n">x_input</span> <span class="o">@</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">down</span><span class="p">)</span>
        <span class="c1"># in case no PCA is used, the encoder is just the identity</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z_pca</span> <span class="o">=</span> <span class="n">x_input</span> <span class="o">*</span> <span class="mi">1</span>

        <span class="c1"># if individual scaling is used, scale every feature individually</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pca_scaling_individual</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_pca</span><span class="p">:</span>
                <span class="c1"># scale by singular values to maintain the right variance</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scale_factor</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">singular_values_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># scale every feature by its maximum value to avoid numerical issues</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scale_factor</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="c1"># if no individual scaling is used, scale the whole data set by its maximum value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scale_factor</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

        <span class="c1"># apply scaling</span>
        <span class="n">z_pca</span> <span class="o">=</span> <span class="n">z_pca</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_factor</span>

        <span class="k">return</span> <span class="n">z_pca</span></div>


<div class="viewcode-block" id="APHIN.build_pca_decoder">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.build_pca_decoder">[docs]</a>
    <span class="k">def</span> <span class="nf">build_pca_decoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_dec</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build a linear decoder which is equivalent to the backprojection of the PCA.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        z_dec : tf.Tensor</span>
<span class="sd">            Decoded PCA tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tf.Tensor</span>
<span class="sd">            Decoded tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># apply scaling</span>
        <span class="n">z_dec</span> <span class="o">=</span> <span class="n">z_dec</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_factor</span>
        <span class="c1"># pca part</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_pca</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">z_dec</span> <span class="o">@</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">up</span><span class="p">)</span>
        <span class="c1"># in case no PCA is used, the decoder is just the identity</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">z_dec</span> <span class="o">*</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">x</span></div>


<div class="viewcode-block" id="APHIN.build_nonlinear_autoencoder">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.build_nonlinear_autoencoder">[docs]</a>
    <span class="k">def</span> <span class="nf">build_nonlinear_autoencoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_pca</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build a fully connected autoencoder with layers of size layer_sizes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        z_pca : tf.Tensor</span>
<span class="sd">            Input to the autoencoder.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            Tuple containing encoded and decoded tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pca_only</span><span class="p">:</span>
            <span class="c1"># Use only PCA and no nonlinear autoencoder</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)(</span><span class="n">z_pca</span><span class="p">)</span>
            <span class="n">z_dec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)(</span><span class="n">z</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">z_dec</span>

        <span class="n">z</span> <span class="o">=</span> <span class="n">z_pca</span>
        <span class="k">for</span> <span class="n">n_neurons</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
                <span class="n">n_neurons</span><span class="p">,</span>
                <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
                <span class="n">activity_regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span><span class="p">,</span>
            <span class="p">)(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduced_order</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)(</span><span class="n">z</span><span class="p">)</span>

        <span class="c1"># new decoder</span>
        <span class="n">x_</span> <span class="o">=</span> <span class="n">z</span>
        <span class="k">for</span> <span class="n">n_neurons</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span><span class="p">):</span>
            <span class="n">x_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">)(</span><span class="n">x_</span><span class="p">)</span>
        <span class="n">z_dec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pca_order</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)(</span><span class="n">x_</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">z_dec</span></div>


<div class="viewcode-block" id="APHIN.train_step">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.train_step">[docs]</a>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform one training step.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inputs : array-like</span>
<span class="sd">            Input data.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            Dictionary containing loss values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># perform forward pass, calculate loss and update weights</span>
        <span class="n">rec_loss</span><span class="p">,</span> <span class="n">dz_loss</span><span class="p">,</span> <span class="n">dx_loss</span><span class="p">,</span> <span class="n">reg_loss</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_loss</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="c1"># update loss tracker</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_tracker</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rec_loss_tracker</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">rec_loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dz_loss_tracker</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">dz_loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dx_loss_tracker</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">dx_loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_loss_tracker</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">reg_loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_tracker</span><span class="o">.</span><span class="n">result</span><span class="p">(),</span>
            <span class="s2">&quot;rec_loss&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">rec_loss_tracker</span><span class="o">.</span><span class="n">result</span><span class="p">(),</span>
            <span class="s2">&quot;dz_loss&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dz_loss_tracker</span><span class="o">.</span><span class="n">result</span><span class="p">(),</span>
            <span class="s2">&quot;dx_loss&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dx_loss_tracker</span><span class="o">.</span><span class="n">result</span><span class="p">(),</span>
            <span class="s2">&quot;reg_loss&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">reg_loss_tracker</span><span class="o">.</span><span class="n">result</span><span class="p">(),</span>
        <span class="p">}</span></div>


<div class="viewcode-block" id="APHIN.test_step">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.test_step">[docs]</a>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform one test step.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inputs : array-like</span>
<span class="sd">            Input data.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            Dictionary containing loss values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rec_loss</span><span class="p">,</span> <span class="n">dz_loss</span><span class="p">,</span> <span class="n">dx_loss</span><span class="p">,</span> <span class="n">reg_loss</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_loss</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_tracker</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rec_loss_tracker</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">rec_loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dz_loss_tracker</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">dz_loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dx_loss_tracker</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">dx_loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_loss_tracker</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">reg_loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
            <span class="s2">&quot;rec_loss&quot;</span><span class="p">:</span> <span class="n">rec_loss</span><span class="p">,</span>
            <span class="s2">&quot;dz_loss&quot;</span><span class="p">:</span> <span class="n">dz_loss</span><span class="p">,</span>
            <span class="s2">&quot;dx_loss&quot;</span><span class="p">:</span> <span class="n">dx_loss</span><span class="p">,</span>
            <span class="s2">&quot;reg_loss&quot;</span><span class="p">:</span> <span class="n">reg_loss</span><span class="p">,</span>
        <span class="p">}</span></div>


<div class="viewcode-block" id="APHIN.calc_latent_time_derivatives">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.calc_latent_time_derivatives">[docs]</a>
    <span class="k">def</span> <span class="nf">calc_latent_time_derivatives</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dx_dt</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate time derivatives of latent variables given the time derivatives of the input variables.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like</span>
<span class="sd">            Full state with shape (n_samples, n_features).</span>
<span class="sd">        dx_dt : array-like</span>
<span class="sd">            Time derivative of state with shape (n_samples, n_features).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            Tuple containing latent variables and their time derivatives.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span>
        <span class="n">dx_dt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">dx_dt</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># forward pass of encoder and time derivative of latent variable</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">t12</span><span class="p">:</span>
            <span class="n">xr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pca_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">t12</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">xr</span><span class="p">)</span>
            <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonlinear_encoder</span><span class="p">(</span><span class="n">xr</span><span class="p">)</span>
        <span class="n">dz_dxr</span> <span class="o">=</span> <span class="n">t12</span><span class="o">.</span><span class="n">batch_jacobian</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">xr</span><span class="p">)</span>

        <span class="c1"># calculate first time derivative of the latent variable by application of the chain rule</span>
        <span class="c1">#   dz_ddt  = dz_dx @ dx_dt</span>
        <span class="c1">#           = dz_dxr @ (V^T @ dx_dt)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">dz_dt</span> <span class="o">=</span> <span class="n">dz_dxr</span> <span class="o">@</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pca_encoder</span><span class="p">(</span><span class="n">dx_dt</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># for convolutional autoencoder data has another shape and must be vectorized first</span>
        <span class="k">except</span> <span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">InvalidArgumentError</span><span class="p">:</span>
            <span class="n">dz_dxr</span><span class="p">,</span> <span class="n">dx_dt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape_conv_data</span><span class="p">(</span>
                <span class="n">dz_dxr</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pca_encoder</span><span class="p">(</span><span class="n">dx_dt</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">dz_dt</span> <span class="o">=</span> <span class="n">dz_dxr</span> <span class="o">@</span> <span class="n">dx_dt</span>
        <span class="n">dz_dt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dz_dt</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">z</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">dz_dt</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span></div>


<div class="viewcode-block" id="APHIN.calc_pca_time_derivatives">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.calc_pca_time_derivatives">[docs]</a>
    <span class="k">def</span> <span class="nf">calc_pca_time_derivatives</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dx_dt</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate time derivatives of PCA variables given the time derivatives of the input variables.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like</span>
<span class="sd">            Full state with shape (n_samples, n_features).</span>
<span class="sd">        dx_dt : array-like</span>
<span class="sd">            Time derivative of state with shape (n_samples, n_features).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            Tuple containing PCA coordinates and their time derivatives.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span>
        <span class="n">dx_dt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">dx_dt</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># forward pass of encoder and time derivative of latent variable</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">t12</span><span class="p">:</span>
            <span class="n">z_pca</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pca_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">t12</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">z_pca</span><span class="p">)</span>

        <span class="c1"># calculate first time derivative of the latent variable by application of the chain rule</span>
        <span class="c1">#   dz_ddt  = dz_dx @ dx_dt</span>
        <span class="c1">#           = dz_dxr @ (V^T @ dx_dt)</span>
        <span class="n">dz_pca_dt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pca_encoder</span><span class="p">(</span><span class="n">dx_dt</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">dz_pca_dt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dz_pca_dt</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">z_pca</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">dz_pca_dt</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span></div>


<div class="viewcode-block" id="APHIN.calc_physical_time_derivatives">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.calc_physical_time_derivatives">[docs]</a>
    <span class="k">def</span> <span class="nf">calc_physical_time_derivatives</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">dz_dt</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate time derivatives of physical variables given the time derivatives of the latent variables.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        z : array-like</span>
<span class="sd">            Latent state with shape (n_samples, r).</span>
<span class="sd">        dz_dt : array-like</span>
<span class="sd">            Time derivative of latent state with shape (n_samples, r).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            Tuple containing physical variables and their time derivatives.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)</span>
        <span class="n">dz_dt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">dz_dt</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># forward pass of encoder and time derivative of latent variable</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">t12</span><span class="p">:</span>
            <span class="n">t12</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">xr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonlinear_decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pca_decoder</span><span class="p">(</span><span class="n">xr</span><span class="p">)</span>
        <span class="n">dxr_dz</span> <span class="o">=</span> <span class="n">t12</span><span class="o">.</span><span class="n">batch_jacobian</span><span class="p">(</span><span class="n">xr</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

        <span class="c1"># calculate first time derivative of the physical variable by application of the chain rule</span>
        <span class="c1">#   dx_ddt  = dx_dz @ dz_dt</span>
        <span class="c1">#           = V dxr_dz @ dz_dt</span>
        <span class="n">dx_dt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pca_decoder</span><span class="p">(</span><span class="n">dxr_dz</span> <span class="o">@</span> <span class="n">dz_dt</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">dx_dt</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span></div>


    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">_get_loss_rec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dx_dt</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate reconstruction loss of autoencoder.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like</span>
<span class="sd">            Full state with shape (n_samples, n_features).</span>
<span class="sd">        dx_dt : array-like</span>
<span class="sd">            Time derivative of state with shape (n_samples, n_features).</span>
<span class="sd">        u : array-like</span>
<span class="sd">            System inputs with shape (n_samples, n_inputs).</span>
<span class="sd">        mu : array-like</span>
<span class="sd">            System parameters with shape (n_samples, n_params).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            Tuple containing individual losses and total loss.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">xr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pca_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonlinear_encoder</span><span class="p">(</span><span class="n">xr</span><span class="p">)</span>
        <span class="n">xr_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonlinear_decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

        <span class="c1"># we only calculate the reconstruction loss for the reconstruction of the pca encoded input</span>
        <span class="c1"># because this is the only trainable part and the computational cost is reduced</span>
        <span class="n">rec_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l_rec</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">xr</span><span class="p">,</span> <span class="n">xr_</span><span class="p">)</span>

        <span class="c1"># for conformity with other get_loss functions return 0 for other losses</span>
        <span class="n">dz_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">dx_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># get model losses (e.g. regularization)</span>
        <span class="n">reg_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">rec_loss</span> <span class="o">+</span> <span class="n">dz_loss</span> <span class="o">+</span> <span class="n">dx_loss</span> <span class="o">+</span> <span class="n">reg_loss</span>

        <span class="k">return</span> <span class="n">rec_loss</span><span class="p">,</span> <span class="n">dz_loss</span><span class="p">,</span> <span class="n">dx_loss</span><span class="p">,</span> <span class="n">reg_loss</span><span class="p">,</span> <span class="n">total_loss</span>

    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dx_dt</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate loss.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like</span>
<span class="sd">            Full state with shape (n_samples, n_features).</span>
<span class="sd">        dx_dt : array-like</span>
<span class="sd">            Time derivative of state with shape (n_samples, n_features).</span>
<span class="sd">        u : array-like</span>
<span class="sd">            System inputs with shape (n_samples, n_inputs).</span>
<span class="sd">        mu : array-like</span>
<span class="sd">            System parameters with shape (n_samples, n_params).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            Tuple containing individual losses and total loss.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># time derivative of intermediate latent space</span>
        <span class="n">dxr_dt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pca_encoder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">dx_dt</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype_</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>

        <span class="c1"># forward pass of encoder and time derivative of latent variable</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">t12</span><span class="p">:</span>
            <span class="c1"># linear projection of input to intermediate latent space</span>
            <span class="n">xr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pca_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">t12</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">xr</span><span class="p">)</span>
            <span class="c1"># nonlinear mapping of intermediate latent space to latent space</span>
            <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonlinear_encoder</span><span class="p">(</span><span class="n">xr</span><span class="p">)</span>
        <span class="n">dz_dxr</span> <span class="o">=</span> <span class="n">t12</span><span class="o">.</span><span class="n">batch_jacobian</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">xr</span><span class="p">)</span>

        <span class="c1"># the second part of the loss calculation is similar for all subclasses and consequently outsourced</span>
        <span class="n">rec_loss</span><span class="p">,</span> <span class="n">dz_loss</span><span class="p">,</span> <span class="n">dx_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_loss_second_part</span><span class="p">(</span>
            <span class="n">xr</span><span class="p">,</span> <span class="n">dz_dxr</span><span class="p">,</span> <span class="n">dxr_dt</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">mu</span>
        <span class="p">)</span>
        <span class="c1"># get model losses (e.g. regularization)</span>
        <span class="n">reg_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_network</span><span class="o">.</span><span class="n">losses</span><span class="p">:</span>
            <span class="n">reg_loss</span> <span class="o">+=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">add_n</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">system_network</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

        <span class="c1"># calculate total loss as weighted sum of individual losses</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">rec_loss</span> <span class="o">+</span> <span class="n">dz_loss</span> <span class="o">+</span> <span class="n">dx_loss</span> <span class="o">+</span> <span class="n">reg_loss</span>

        <span class="k">return</span> <span class="n">rec_loss</span><span class="p">,</span> <span class="n">dz_loss</span><span class="p">,</span> <span class="n">dx_loss</span><span class="p">,</span> <span class="n">reg_loss</span><span class="p">,</span> <span class="n">total_loss</span>

<div class="viewcode-block" id="APHIN.get_loss_second_part">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.get_loss_second_part">[docs]</a>
    <span class="k">def</span> <span class="nf">get_loss_second_part</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xr</span><span class="p">,</span> <span class="n">dz_dxr</span><span class="p">,</span> <span class="n">dxr_dt</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Second part of loss calculation (loss calclulation is split into two parts as the second part differs for</span>
<span class="sd">        the different autoencoder implementations, while the first part remains the same).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        xr : tf.Tensor</span>
<span class="sd">            Intermediate latent space tensor.</span>
<span class="sd">        dz_dxr : tf.Tensor</span>
<span class="sd">            Jacobian of latent variables with respect to intermediate latent space.</span>
<span class="sd">        dxr_dt : tf.Tensor</span>
<span class="sd">            Time derivative of intermediate latent space.</span>
<span class="sd">        z : tf.Tensor</span>
<span class="sd">            Latent variables.</span>
<span class="sd">        u : tf.Tensor</span>
<span class="sd">            System inputs.</span>
<span class="sd">        mu : tf.Tensor</span>
<span class="sd">            System parameters.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            Tuple containing individual losses.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># calculate first time derivative of the latent variable by application of the chain rule</span>
        <span class="c1">#   dz_ddt  = dz_dx @ dx_dt</span>
        <span class="c1">#           = dz_dxr @ (V^T @ dx_dt)</span>
        <span class="n">dz_dt</span> <span class="o">=</span> <span class="n">dz_dxr</span> <span class="o">@</span> <span class="n">dxr_dt</span>

        <span class="c1"># calculate left hand side of ODE system (relevant for descriptor systems)</span>
        <span class="n">dxr_dt_lhs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_layer</span><span class="o">.</span><span class="n">lhs</span><span class="p">(</span><span class="n">dxr_dt</span><span class="p">)</span>
        <span class="n">dz_dt_lhs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_layer</span><span class="o">.</span><span class="n">lhs</span><span class="p">(</span><span class="n">dz_dt</span><span class="p">)</span>

        <span class="c1"># system_network approximation of the time derivative of the latent variable</span>
        <span class="n">system_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_network</span><span class="p">([</span><span class="n">z</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">mu</span><span class="p">])</span>
        <span class="n">dz_dt_system</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">system_pred</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># forward pass of decoder and time derivative of reconstructed variable</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">t22</span><span class="p">:</span>
            <span class="n">t22</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">xr_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonlinear_decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="c1"># we only calculate this if the loss is not zero to save computational cost</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">l_dx</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">dxr_dz</span> <span class="o">=</span> <span class="n">t22</span><span class="o">.</span><span class="n">batch_jacobian</span><span class="p">(</span><span class="n">xr_</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
            <span class="c1"># reshape in case of convolutional autoencoder</span>
            <span class="n">dxr_dz</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape_dxr_dz</span><span class="p">(</span><span class="n">dxr_dz</span><span class="p">)</span>
            <span class="c1"># calculate first time derivative of the reconstructed state by application of the chain rule</span>
            <span class="n">dxf_dt</span> <span class="o">=</span> <span class="n">dxr_dz</span> <span class="o">@</span> <span class="n">dz_dt_system</span>
            <span class="n">dx_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l_dx</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dxf_dt</span><span class="p">,</span> <span class="n">dxr_dt_lhs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dx_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="c1"># calculate losses</span>
        <span class="n">rec_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l_rec</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">xr</span><span class="p">,</span> <span class="n">xr_</span><span class="p">)</span>
        <span class="n">dz_loss</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">l_dz</span>
            <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dz_dt_lhs</span><span class="p">,</span> <span class="n">dz_dt_system</span><span class="p">)</span>
            <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">dz_dt_lhs</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">rec_loss</span><span class="p">,</span> <span class="n">dz_loss</span><span class="p">,</span> <span class="n">dx_loss</span></div>


<div class="viewcode-block" id="APHIN.reshape_dxr_dz">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.reshape_dxr_dz">[docs]</a>
    <span class="k">def</span> <span class="nf">reshape_dxr_dz</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dxr_dz</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reshape data for conformity with Convolutional Autoencoder.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dxr_dz : tf.Tensor</span>
<span class="sd">            Jacobian of reconstructed state with respect to latent variables.</span>

<span class="sd">        Returns</span>
<span class="sd">        ----------</span>
<span class="sd">        dxr_dz: tf.Tensor</span>
<span class="sd">            Same as input</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">dxr_dz</span></div>


<div class="viewcode-block" id="APHIN.vis_modes">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.vis_modes">[docs]</a>
    <span class="k">def</span> <span class="nf">vis_modes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mode_ids</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">latent_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">block</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Visualize the reconstruction of the reduced coefficients of the PCA modes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like</span>
<span class="sd">            Original dataset.</span>
<span class="sd">        mode_ids : int or array-like, optional</span>
<span class="sd">            Scalar (plots mode_ids) or array (plots modes with indices from mode_ids).</span>
<span class="sd">        latent_ids : int or array-like, optional</span>
<span class="sd">            Scalar (plots latent_ids) or array (plots modes with indices from latent_ids).</span>
<span class="sd">        block : bool, optional</span>
<span class="sd">            Whether to block the display of the plot.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">modes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pca_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">mode_ids</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span>
        <span class="p">):</span>  <span class="c1"># check if n_modes is an array</span>
            <span class="n">n_modes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mode_ids</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># n_modes is scalar: plot modes from 1:n_modes</span>
            <span class="n">n_modes</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">mode_ids</span><span class="p">,</span> <span class="n">modes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">mode_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_modes</span><span class="p">))</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonlinear_encoder</span><span class="p">(</span><span class="n">modes</span><span class="p">)</span>
        <span class="n">modes_rec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonlinear_decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

        <span class="c1"># define number of latent coordinate plots (default: plot all latent coordinates)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">latent_ids</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span>
        <span class="p">):</span>  <span class="c1"># check if n_latent is an array</span>
            <span class="n">n_latent_plots</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">latent_ids</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">latent_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># show all latent coordinates</span>
            <span class="n">n_latent_plots</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduced_order</span>
            <span class="n">latent_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_latent_plots</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># n_latent is scalar: plot latent coordinates from 1:n_latent</span>
            <span class="n">n_latent_plots</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">latent_ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduced_order</span><span class="p">)</span>
            <span class="n">latent_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_latent_plots</span><span class="p">))</span>

        <span class="c1"># visualize modes in subplots</span>
        <span class="n">n_plots</span> <span class="o">=</span> <span class="n">n_modes</span> <span class="o">+</span> <span class="n">n_latent_plots</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_pca</span> <span class="k">else</span> <span class="n">n_latent_plots</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">n_plots</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># plot latent variables</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_latent_plots</span><span class="p">):</span>
            <span class="n">latent_id</span> <span class="o">=</span> <span class="n">latent_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">[:,</span> <span class="n">latent_id</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;z_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># plot PCA modes (original and reconstructed by latent variables)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_pca</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_modes</span><span class="p">):</span>
                <span class="n">mode_id</span> <span class="o">=</span> <span class="n">mode_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">axs</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">n_latent_plots</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">modes</span><span class="p">[:,</span> <span class="n">mode_id</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Original&quot;</span><span class="p">)</span>
                <span class="n">axs</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">n_latent_plots</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                    <span class="n">modes_rec</span><span class="p">[:,</span> <span class="n">mode_id</span><span class="p">],</span> <span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Reconstructed&quot;</span>
                <span class="p">)</span>
                <span class="n">axs</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">n_latent_plots</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
                    <span class="sa">rf</span><span class="s2">&quot;Mode </span><span class="si">{</span><span class="n">mode_id</span><span class="si">}</span><span class="s2">, $\sigma = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">singular_values</span><span class="p">[</span><span class="n">mode_id</span><span class="p">]</span><span class="si">:</span><span class="s2">.4g</span><span class="si">}</span><span class="s2">$&quot;</span>
                <span class="p">)</span>
                <span class="c1"># add legend</span>
                <span class="n">axs</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">n_latent_plots</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="n">block</span><span class="p">)</span></div>


    <span class="c1"># @tf.function</span>
<div class="viewcode-block" id="APHIN.encode">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.encode">[docs]</a>
    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Encode full state.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like</span>
<span class="sd">            Full state with shape (n_samples, n_features, n_dof_per_feature).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        z : array-like</span>
<span class="sd">            Latent variable with shape (n_samples, reduced_order).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span></div>


    <span class="c1"># @tf.function</span>
<div class="viewcode-block" id="APHIN.decode">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.decode">[docs]</a>
    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Decode latent variable.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        z : array-like</span>
<span class="sd">            Latent variable with shape (n_samples, reduced_order).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        x : array-like</span>
<span class="sd">            Full state with shape (n_samples, n_features, n_dof_per_feature).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x_rec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_rec</span></div>


    <span class="c1"># @tf.function</span>
<div class="viewcode-block" id="APHIN.reconstruct">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.reconstruct">[docs]</a>
    <span class="k">def</span> <span class="nf">reconstruct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reconstruct full state.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like</span>
<span class="sd">            Full state with shape (n_samples, n_features, n_dof_per_feature).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        x_rec : array-like</span>
<span class="sd">            Reconstructed full state with shape (n_samples, n_features, n_dof_per_feature).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x_rec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_rec</span></div>


    <span class="c1"># %% time integrator for latent variables (pH structure-preserving integrator)</span>
<div class="viewcode-block" id="APHIN.implicit_midpoint">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.implicit_midpoint">[docs]</a>
    <span class="k">def</span> <span class="nf">implicit_midpoint</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">t0</span><span class="p">,</span> <span class="n">z0</span><span class="p">,</span> <span class="n">t_bound</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">decomp_option</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate time integration of linear ODE through implicit midpoint rule</span>
<span class="sd">        ODE system E*dz_dt = A*z + B*u</span>
<span class="sd">        Theory:</span>
<span class="sd">        We got a pH-system E*Dx = (J-D)*Q*x + B*u</span>
<span class="sd">        we define A:=(J-D)*Q and the RHS as f(t,x)</span>
<span class="sd">        use the differential slope equation at midpoint</span>
<span class="sd">        (x(t+h)-x(t))/h=Dx(t+h/2)=E^-1 * f(t+h/2,x(t+h/2))</span>
<span class="sd">        since x(t+h/2) is unknown we use the approximation</span>
<span class="sd">        x(t+h/2) = 1/2*(x(t)+x(t+h))</span>
<span class="sd">        insert the linear system into the differential equation leads to</span>
<span class="sd">        x(t+h) = x(t) + h * E^-1 *(1/2*A*(x(t)+x(t+h))+ B*u(t+h/2))</span>
<span class="sd">        reformulate the equation to</span>
<span class="sd">        (E-h/2*A)x(t+h) = (E+h/2*A)*x(t) + h*B*u(t+h/2)</span>
<span class="sd">        solve the linear equation system, e.g. via LU-decomposition</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        t0 : float</span>
<span class="sd">            Initial time.</span>
<span class="sd">        z0 : array-like</span>
<span class="sd">            Initial state vector.</span>
<span class="sd">        t_bound : float</span>
<span class="sd">            End time.</span>
<span class="sd">        step_size : float</span>
<span class="sd">            Constant step width.</span>
<span class="sd">        B : array-like, optional</span>
<span class="sd">            Input matrix, default is None (will be set to zero).</span>
<span class="sd">        u : callable, optional</span>
<span class="sd">            Input function at time midpoints, default is None (will be set to zero).</span>
<span class="sd">        decomp_option : int, optional</span>
<span class="sd">            Option for decomposition (1-lu_solve), default is 1.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        z : array-like</span>
<span class="sd">            Integrated state vector.</span>
<span class="sd">        -----------------------------------------------------------------------</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># todo: define self variables that are used</span>

        <span class="n">integrators</span><span class="o">.</span><span class="n">implicit_midpoint</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">E</span><span class="p">,</span> <span class="n">t0</span><span class="p">,</span> <span class="n">z0</span><span class="p">,</span> <span class="n">t_bound</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">decomp_option</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="APHIN.get_projection_properties">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.get_projection_properties">[docs]</a>
    <span class="k">def</span> <span class="nf">get_projection_properties</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_test</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">file_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute and save the projection and Jacobian error.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like, optional</span>
<span class="sd">            Training data.</span>
<span class="sd">        x_test : array-like, optional</span>
<span class="sd">            Test data.</span>
<span class="sd">        file_dir : str, optional</span>
<span class="sd">            Directory to save the projection properties.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            Tuple containing projection and Jacobian errors for training and test data.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">projection_error</span><span class="p">,</span> <span class="n">jacobian_error</span><span class="p">,</span> <span class="n">projection_error_test</span><span class="p">,</span> <span class="n">jacobian_error_test</span> <span class="o">=</span> <span class="p">[</span>
            <span class="kc">None</span>
        <span class="p">]</span> <span class="o">*</span> <span class="mi">4</span>
        <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">projection_error</span><span class="p">,</span> <span class="n">jacobian_error</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_properties</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">x_test</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">projection_error_test</span><span class="p">,</span> <span class="n">jacobian_error_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_properties</span><span class="p">(</span>
                <span class="n">x_test</span>
            <span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_dir</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">text_file</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRAIN projection error: </span><span class="si">{</span><span class="n">projection_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">text_file</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRAIN jacobian error: </span><span class="si">{</span><span class="n">jacobian_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">text_file</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">x_test</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TEST projection error: </span><span class="si">{</span><span class="n">projection_error_test</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">text_file</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TEST jacobian error: </span><span class="si">{</span><span class="n">jacobian_error_test</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">text_file</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">projection_error</span><span class="p">,</span>
            <span class="n">jacobian_error</span><span class="p">,</span>
            <span class="n">projection_error_test</span><span class="p">,</span>
            <span class="n">jacobian_error_test</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="APHIN.projection_properties">
<a class="viewcode-back" href="../../../aphin.identification.html#aphin.identification.aphin.APHIN.projection_properties">[docs]</a>
    <span class="k">def</span> <span class="nf">projection_properties</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the projection and Jacobian error.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like</span>
<span class="sd">            Input data.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            Tuple containing projection error and Jacobian error.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># we only need to evaluate the nonlinear autoencoder since the linear one is a projection per definition</span>

        <span class="c1"># forward pass of encoder and time derivative of latent variable</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">t1</span><span class="p">:</span>
            <span class="n">t1</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="c1"># linear projection of input to intermediate latent space</span>
            <span class="n">v_rec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonlinear_decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">jac_z</span> <span class="o">=</span> <span class="n">t1</span><span class="o">.</span><span class="n">batch_jacobian</span><span class="p">(</span><span class="n">v_rec</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">t2</span><span class="p">:</span>
            <span class="n">t2</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">v_rec</span><span class="p">)</span>
            <span class="c1"># nonlinear mapping of intermediate latent space to latent space</span>
            <span class="n">z_rec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonlinear_encoder</span><span class="p">(</span><span class="n">v_rec</span><span class="p">)</span>
        <span class="n">jac_x</span> <span class="o">=</span> <span class="n">t2</span><span class="o">.</span><span class="n">batch_jacobian</span><span class="p">(</span><span class="n">z_rec</span><span class="p">,</span> <span class="n">v_rec</span><span class="p">)</span>

        <span class="c1"># calculate to which extent the autoencoder meets the projection properties</span>
        <span class="c1">#   1. enc(dec(z)) == z</span>
        <span class="n">projection_error</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">z_rec</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
            <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="c1">#   2. jacobian_z(dec(z)) @ jacobian_dec(z)(z) == I</span>
        <span class="n">jacobian_error</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduced_order</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">jac_x</span> <span class="o">@</span> <span class="n">jac_z</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">projection_error</span><span class="p">,</span> <span class="n">jacobian_error</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Jonas Kneifl, Johannes Rettberg, Julius Herb.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>