# %% General settings
setup_matplotlib: False  # Show plots and visualization


# %% General identification framework settings
experiment: final_new_data_var_exp_l_rec0.1_l_dz1_l_dx0.001 #    name of the experiment
load_network: False  # train the network or load the last pre-trained one
sim_name: sim_onlyHeat_1Point_smallHalton_newQ_d3_samp100  # sim_onlyHeat_1Point_smallHalton_d3_samp100
file_url: https://darus.uni-stuttgart.de/file.xhtml?persistentId=doi:10.18419/darus-4418/1#
ref_coords: disc_ref_coords.npy
faces:  disc_faces.npy

seed: 1 #  For reproducibility

# for first time use, creates data from .txt file from Abaqus
create_data_from_txt: False
# scaling_values: (list) scalar scalar values that each domain, defined by domain_split_vals, should be scaled with, if {None} it is scaled by the maximum value of each domain
scaling_values: [1000,0.00001,0.00001] #[theta_scaling, disp_scaling, optional: velocity_scaling]
# domain_split_vals: (list) integers that define the number of dofs for each domain, sum of all values needs to conincide with n_dn. If {None} it is considered as a single domain
domain_split_vals: [1,3,3] # [theta, displacement, optional: velocity]
domain_names: ["temp","disp","vel"]
desired_bounds: [0, 1]   # desired bounds after scaling for u and mu
use_velocities: True

# decrease number of simulations
num_sim: 48 # Null if number of simulations should not be decreased or integer with the target number of simulations

# decrease number of time steps
num_time_steps: Null # {Null} if number of time steps should not be decreases or integer with the target number of time steps per trajectory

# train-test split
train_test_split_method: rand # sim_idx | rand, sim_idx uses predefined indices, rand uses test_size value
test_size: 20

# filter data (using a savgol filter)
filter_data: False 
# %% Disc brake data settings (get information from loaded data)
n_u: 1      # number of inputs
n_mu: 2     # number of parameters (not varying inputs)

# %% identification settings
r: 3 #  reduced order
use_pca: True  # use PCA for the input
n_pca: 8  # number of PCA components
pca_scaling: True  # scale the PCA components
pca_comparison: True
pca_only: False  # only use PCA components without nonlinear autoencoder
l_rec: 0.1 #  loss weight for the reconstruction
l_dz: 1 #  loss weight for the dz
l_dx: 0.001 #  loss weight for the dx
l1: 0.0000000001  # L1 regularization
l2: 0  # L2 regularization
n_epochs: 2000 #  number of epochs
batch_size: 256  # batch size
layer_sizes_ph: # layer sizes
  - 32  # first layer
  - 32  # second layer
  - 32  # third layer
layer_sizes_ae: # layer sizes
  - 64  # first layer
  - 32 # second layer
  - 16  # third layer
activation_ae: elu  # activation function
activation_ph: elu  # activation function
lr: 0.00025  # learning rate
tensorboard: False  # Save model information for analysis in tensorboard