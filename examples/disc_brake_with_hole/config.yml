# %% General settings
setup_matplotlib: False  # Show plots and visualization


# %% General identification framework settings
experiment: db_with_hole_convex_multExp #    name of the experiment
load_network: False  # train the network or load the last pre-trained one
sim_name: disc_brake_with_hole_low_freq_convex  # sim_onlyHeat_1Point_smallHalton_d3_samp100
file_url: https://darus.uni-stuttgart.de/api/access/datafile/:persistentId?persistentId=doi:10.18419/darus-4418/1
ref_coords: disc_ref_coords.npy
faces:  disc_faces.npy
t_end: 0.2 # truncate when reading from .txt to reduce data memory

seed: 1 #  For reproducibility

# scaling_values: (list) scalar scalar values that each domain, defined by domain_split_vals, should be scaled with, if {None} it is scaled by the maximum value of each domain
scaling_values: Null #[1000,0.00001,0.00001] #[theta_scaling, disp_scaling, optional: velocity_scaling]
# domain_split_vals: (list) integers that define the number of dofs for each domain, sum of all values needs to conincide with n_dn. If {None} it is considered as a single domain
domain_split_vals: [1,3,3] # [theta, displacement, optional: velocity]
domain_names: ["temp","disp","vel"]
# domain_split_vals: [1,3] # [theta, displacement, optional: velocity]
# domain_names: ["temp","disp"]
desired_bounds: [0, 1]   # desired bounds after scaling for u and mu
use_velocities: False # might be included in data already

# decrease number of simulations
num_sim: Null # Null if number of simulations should not be decreased or integer with the target number of simulations

# decrease number of time steps
num_time_steps: Null # {Null} if number of time steps should not be decreased or integer with the target number of time steps per trajectory

# train-test split
train_test_split_method: sim_idx # sim_idx | rand, sim_idx uses predefined indices, rand uses test_size value
test_size: 20 # required for rand

# filter data (using a savgol filter)
filter_data: False 
interp_equidis_t: True
window: 20
order: 3

# cut start and end data
cut_time_start_and_end: True

# %% Disc brake data settings (get information from loaded data)
n_u: 3      # number of inputs
n_mu: 2     # number of parameters (not varying inputs)

ph_layer: phq  # ph | phq

# %% identification settings
r: 16 
#   reduced order
use_pca: True 
#  use PCA for the input
n_pca: 60  # number of PCA components
pca_scaling: False  # scale the PCA components
pca_comparison: True
pca_only: False  # only use PCA components without nonlinear autoencoder
l_rec: 10 #  loss weight for the reconstruction
l_dz: 0.01 #  loss weight for the dz
l_dx: 0.0000001 #  loss weight for the dx
l1: 0.0000000001  # L1 regularization
l2: 0  # L2 regularization
n_epochs: 1400 
#   number of epochs
batch_size: 128  # batch size
layer_sizes_ph: # layer sizes
  - 32  # first layer
  - 64  # second layer
  - 128  # third layer
layer_sizes_ae: # layer sizes
  - 60  # first layer
  - 50  # first layer
  - 40 # second layer
  - 30  # third layer
  # - 16  # third layer
activation_ae: elu  # activation function
activation_ph: elu  # activation function
lr: 0.000025  # learning rate
tensorboard: False  # Save model information for analysis in tensorboard
save_many_weights: False